{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a167c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import dataset\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7629ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f656ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self, device,\n",
    "                    max_len,\n",
    "                    num_tokens,\n",
    "                    dim=64,\n",
    "                    nhead=8,\n",
    "                    num_encoders=2,\n",
    "                    num_decoders=2,\n",
    "                    d_feedforward=1024,\n",
    "                    batch_first=True):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.device = device\n",
    "        self.tokens = num_tokens\n",
    "        ##Create encoder layers##\n",
    "        self.src_emb = nn.Embedding(num_tokens, dim)\n",
    "        self.tgt_emb = nn.Embedding(num_tokens, dim)\n",
    "        self.pos_emb = nn.Embedding(max_len, dim)\n",
    "        ##Create Transformer##\n",
    "        self.transformer = nn.Transformer(d_model=dim, nhead=nhead,num_encoder_layers=num_encoders,     \\\n",
    "                                         num_decoder_layers=num_decoders, dim_feedforward=d_feedforward, \\\n",
    "                                         batch_first=batch_first)\n",
    "        ##Create Final Linear Layer##\n",
    "        self.linear = nn.Linear(dim, num_tokens)\n",
    "        ##Create TimeStep Input##\n",
    "        self.timesteps = torch.Tensor([[i for i in range(max_len)]]).type(torch.LongTensor).to(device)\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask, src_pad_mask, tgt_pad_mask):\n",
    "        pos_emb = self.pos_emb(self.timesteps)\n",
    "        src_emb = self.src_emb(src)\n",
    "        tgt_emb = self.tgt_emb(tgt)\n",
    "        src_in = pos_emb + src_emb\n",
    "        tgt_in = pos_emb + tgt_emb\n",
    "        trans_out = self.transformer(src_in, tgt_in, src_mask, tgt_mask, None, src_pad_mask, tgt_pad_mask)\n",
    "        return (self.linear(trans_out))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13553b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=d)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt, dset):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=d).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == dset.TOKENS[\"<PAD>\"])\n",
    "    tgt_padding_mask = (tgt == dset.TOKENS[\"<PAD>\"])\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394c7778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11,  4, 11,  2, 13, 14, 14, 14, 14],\n",
      "        [11,  5, 11, 11,  2, 13, 14, 14, 14],\n",
      "        [ 3, 12, 11,  2, 13, 14, 14, 14, 14],\n",
      "        [11,  2, 12,  4, 13, 14, 14, 14, 14]], dtype=torch.int32) tensor([[15, 11,  6, 13, 14, 14, 14, 14, 14],\n",
      "        [15, 11,  3, 13, 14, 14, 14, 14, 14],\n",
      "        [15, 11,  6, 13, 14, 14, 14, 14, 14],\n",
      "        [15, 11,  8, 13, 14, 14, 14, 14, 14]], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False]],\n",
       "        device='cuda:0'),\n",
       " tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([[False, False, False, False, False,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False,  True,  True,  True],\n",
       "         [False, False, False, False, False,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False,  True,  True,  True,  True]]),\n",
       " tensor([[False, False, False, False,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False,  True,  True,  True,  True,  True]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = dataset.Arithmetic(10)\n",
    "x,y,y_ = dset.get_batch(4)\n",
    "print(x,y)\n",
    "create_mask(x,y,dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69da0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, crit, device, iterations, dset, batch_size, print_freq, scheduler):\n",
    "    running_loss = 0\n",
    "    for it in range(iterations):\n",
    "        x,y,y_ = dset.get_batch(batch_size)\n",
    "        x = x.type(torch.LongTensor).to(device)\n",
    "        y = y.type(torch.LongTensor).to(device)\n",
    "        y_ = y_.type(torch.LongTensor).to(device)\n",
    "        \n",
    "        src_mask, tgt_mask, src_pad_mask, tgt_pad_mask = create_mask(x,y,dset)\n",
    "        model_out = model(x, y, src_mask, tgt_mask, src_pad_mask, tgt_pad_mask)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        loss = crit(model_out.reshape(-1, model_out.shape[-1]), y_.reshape(-1))\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        running_loss+=loss.item()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if (it+1) % print_freq == 0:\n",
    "            print(\"Iteration:\",it+1,\"Loss:\",running_loss/print_freq)\n",
    "            running_loss=0\n",
    "            \n",
    "def convert(expression:str, dset, model, device):\n",
    "    ##Convert String to a tensor##\n",
    "    src = torch.tensor([dset.tokenize_expression(expression)]).to(device)\n",
    "    src = src[:, 1:]\n",
    "    print(dset.max_len)\n",
    "    print(src.shape)\n",
    "    ##Set up output##\n",
    "    y = torch.ones(1, dset.max_len).fill_(dset.TOKENS[\"<PAD>\"]).type(torch.long).to(device)\n",
    "    y[0,0] = dset.TOKENS[\"<SOS>\"]\n",
    "    model.eval()\n",
    "    for i in range(dset.max_len-1):\n",
    "        src_mask, tgt_mask, src_pad_mask, tgt_pad_mask = create_mask(src,y,dset)\n",
    "        out = model(src, y, src_mask, tgt_mask, src_pad_mask, tgt_pad_mask)\n",
    "        probs = out[0,i]\n",
    "        next_token = torch.argmax(probs,dim=0)\n",
    "        y[0, i+1] = next_token\n",
    "        if next_token == dset.TOKENS[\"<EOS>\"]:\n",
    "            break\n",
    "    y = y.squeeze(0)\n",
    "    y = y.tolist()\n",
    "    return dset.get_str(y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c319023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "torch.Size([1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<SOS><EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = dataset.Arithmetic(100)\n",
    "model = Baseline(d, dset.max_len,dset.num_tokens,num_encoders=1,\n",
    "                    num_decoders=1, dim=128).to(d)\n",
    "op = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(op, step_size=10000, gamma=.95)\n",
    "crit = nn.CrossEntropyLoss(ignore_index=dset.TOKENS[\"<PAD>\"])\n",
    "convert(\"1+1\", dset, model, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7bdaee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000 Loss: 0.1666370017975569\n",
      "Iteration: 2000 Loss: 0.13526613587886094\n",
      "Iteration: 3000 Loss: 0.10743810536339879\n",
      "Iteration: 4000 Loss: 0.09017679917812348\n",
      "Iteration: 5000 Loss: 0.07490667941607534\n",
      "Iteration: 6000 Loss: 0.06688066721521319\n",
      "Iteration: 7000 Loss: 0.05998076453059912\n",
      "Iteration: 8000 Loss: 0.05215799659304321\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optim, crit, device, iterations, dset, batch_size, print_freq, scheduler)\u001b[0m\n\u001b[1;32m      7\u001b[0m y_ \u001b[38;5;241m=\u001b[39m y_\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m src_mask, tgt_mask, src_pad_mask, tgt_pad_mask \u001b[38;5;241m=\u001b[39m create_mask(x,y,dset)\n\u001b[0;32m---> 10\u001b[0m model_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_pad_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_pad_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m crit(model_out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, model_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), y_\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m, in \u001b[0;36mBaseline.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, src_pad_mask, tgt_pad_mask)\u001b[0m\n\u001b[1;32m     31\u001b[0m src_in \u001b[38;5;241m=\u001b[39m pos_emb \u001b[38;5;241m+\u001b[39m src_emb\n\u001b[1;32m     32\u001b[0m tgt_in \u001b[38;5;241m=\u001b[39m pos_emb \u001b[38;5;241m+\u001b[39m tgt_emb\n\u001b[0;32m---> 33\u001b[0m trans_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_pad_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_pad_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(trans_out))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:146\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 146\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(tgt, memory, tgt_mask\u001b[38;5;241m=\u001b[39mtgt_mask, memory_mask\u001b[38;5;241m=\u001b[39mmemory_mask,\n\u001b[1;32m    148\u001b[0m                       tgt_key_padding_mask\u001b[38;5;241m=\u001b[39mtgt_key_padding_mask,\n\u001b[1;32m    149\u001b[0m                       memory_key_padding_mask\u001b[38;5;241m=\u001b[39mmemory_key_padding_mask)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:238\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m src_key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     why_not_sparsity_fast_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc_key_padding_mask was None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (((\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask_check\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_check)\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_nested_tensor_from_mask_left_aligned(src, \u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_not\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)):\n\u001b[1;32m    239\u001b[0m     why_not_sparsity_fast_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask_check enabled, and src and src_key_padding_mask was not left aligned\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mis_nested:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, op, crit, d, 100000, dset, 128, 1000, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3098de71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "torch.Size([1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<SOS>200<EOS><PAD><PAD><PAD><PAD><PAD><PAD>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(\"20*10\", dset, model, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403cc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
